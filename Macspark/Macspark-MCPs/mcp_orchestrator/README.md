# MCP Orchestrator

[![Python 3.10+](https://img.shields.io/badge/python-3.10+-blue.svg)](https://www.python.org/downloads/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)
[![Code style: black](https://img.shields.io/badge/code%20style-black-000000.svg)](https://github.com/psf/black)

> **Servidor MCP h√≠brido para orquestra√ß√£o de m√∫ltiplos agentes de IA com fallback inteligente**

O MCP Orchestrator √© um servidor [Model Context Protocol (MCP)](https://modelcontextprotocol.io/) que integra m√∫ltiplos provedores de IA (APIs, CLIs e LLMs locais) com fallback autom√°tico, permitindo alta disponibilidade e otimiza√ß√£o de custos.

## üöÄ Caracter√≠sticas

- **M√∫ltiplos Agentes**: Claude API/CLI, Gemini API/CLI, OpenAI, Mistral, Cohere, Perplexity
- **LLMs Locais**: Ollama, LM Studio (gratuitos e privados)
- **Fallback Inteligente**: Altern√¢ncia autom√°tica entre agentes em caso de falha
- **Otimiza√ß√£o de Custos**: Prioriza√ß√£o de agentes gratuitos (CLIs, LLMs locais)
- **Alta Disponibilidade**: M√∫ltiplas op√ß√µes de fallback garantem resposta sempre
- **Arquitetura Extens√≠vel**: F√°cil adi√ß√£o de novos agentes e ferramentas
- **Logging Estruturado**: Logs detalhados para monitoramento e debugging
- **Configura√ß√£o Flex√≠vel**: Suporte a vari√°veis de ambiente e arquivos de config

## üìã Pr√©-requisitos

- Python 3.10+
- (Opcional) Docker para LLMs locais
- (Opcional) CLIs do Claude e Gemini instalados
- (Opcional) Ollama ou LM Studio para LLMs locais

## üõ†Ô∏è Instala√ß√£o

### M√©todo 1: Instala√ß√£o Local

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd mcp_orchestrator

# Crie ambiente virtual
python -m venv venv
source venv/bin/activate  # Linux/Mac
# ou
venv\Scripts\activate     # Windows

# Instale depend√™ncias
pip install -r requirements.txt

# Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env com suas chaves de API
```

### M√©todo 2: Docker

```bash
# Clone o reposit√≥rio
git clone <repository-url>
cd mcp_orchestrator

# Configure vari√°veis de ambiente
cp .env.example .env
# Edite .env

# Execute com Docker Compose
docker-compose up -d
```

### M√©todo 3: Script Automatizado

```bash
# Execute o script de instala√ß√£o
chmod +x scripts/install.sh
./scripts/install.sh
```

## ‚öôÔ∏è Configura√ß√£o

### Vari√°veis de Ambiente

Copie `.env.example` para `.env` e configure:

```bash
# API Keys (opcionais)
ANTHROPIC_API_KEY="sk-ant-..."      # Claude API
GOOGLE_API_KEY="AIza..."            # Gemini API
OPENAI_API_KEY="sk-..."             # OpenAI API
MISTRAL_API_KEY="..."               # Mistral API
COHERE_API_KEY="..."                # Cohere API
PERPLEXITY_API_KEY="pplx-..."       # Perplexity API

# LLMs Locais (opcionais)
OLLAMA_BASE_URL="http://localhost:11434"
LM_STUDIO_BASE_URL="http://localhost:1234/v1"

# Configura√ß√µes do Servidor
LOG_LEVEL="INFO"
TIMEOUT=30
MAX_RETRIES=3
```

### Configura√ß√£o de Agentes

Edite `config/agents.yaml` para personalizar:

```yaml
agents:
  claude_api:
    enabled: true
    priority: 1
    model: "claude-3-sonnet-20240229"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_cli", "gemini_api", "gemini_cli"]
```

## üöÄ Uso

### Iniciar o Servidor

```bash
# M√©todo direto
python src/mcp_orchestrator/server.py

# Via m√≥dulo
python -m mcp_orchestrator.server

# Via Docker
docker-compose up -d
```

### Integra√ß√£o com Clientes MCP

#### Cursor

Adicione ao `settings.json` do Cursor:

```json
{
  "mcp": {
    "servers": {
      "orchestrator": {
        "command": "python",
        "args": ["/caminho/para/mcp_orchestrator/src/mcp_orchestrator/server.py"]
      }
    }
  }
}
```

#### Claude Desktop

Adicione ao `claude_desktop_config.json`:

```json
{
  "mcpServers": {
    "orchestrator": {
      "command": "python",
      "args": ["/caminho/para/mcp_orchestrator/src/mcp_orchestrator/server.py"]
    }
  }
}
```

### Exemplos de Uso

#### 1. Resposta B√°sica

```python
# Via MCP client
response = mcp_client.call_tool("get_ai_response", {
    "prompt": "Explique o que √© intelig√™ncia artificial",
    "agent": "claude_api"
})
```

#### 2. Com Fallback Autom√°tico

```python
# Se claude_api falhar, automaticamente tenta claude_cli, depois gemini_api
response = mcp_client.call_tool("get_ai_response", {
    "prompt": "Analise este c√≥digo Python",
    "agent": "claude_api",
    "params": {"max_tokens": 1000}
})
```

#### 3. Usando LLM Local

```python
# Usa Ollama local (gratuito)
response = mcp_client.call_tool("get_ai_response", {
    "prompt": "Gere um script de backup",
    "agent": "ollama",
    "params": {"model": "llama3.1:8b"}
})
```

## üß™ Testes

```bash
# Instalar depend√™ncias de desenvolvimento
pip install -r requirements-dev.txt

# Executar testes
pytest tests/ -v

# Com cobertura
pytest tests/ --cov=mcp_orchestrator --cov-report=html

# Linting
black src/ tests/
isort src/ tests/
flake8 src/ tests/
mypy src/
```

## üìä Monitoramento

### Logs

Os logs s√£o escritos em:
- `stderr`: Logs de debug e erro
- `logs/mcp_orchestrator.log`: Logs estruturados
- `logs/errors.log`: Apenas erros

### M√©tricas

Acesse m√©tricas em tempo real:

```bash
# Health check
curl http://localhost:8000/health

# M√©tricas Prometheus
curl http://localhost:8000/metrics
```

### Dashboard Grafana

Acesse o dashboard em `http://localhost:3000` (se configurado).

## üîß Troubleshooting

### Problemas Comuns

#### 1. "Claude CLI not installed"
```bash
# Instale o Claude CLI
npm install -g @anthropic-ai/claude
```

#### 2. "Ollama connection failed"
```bash
# Inicie o Ollama
ollama serve

# Baixe um modelo
ollama pull llama3.1:8b
```

#### 3. "API key not valid"
```bash
# Verifique suas chaves no .env
cat .env | grep API_KEY
```

### Logs Detalhados

```bash
# Aumentar n√≠vel de log
export LOG_LEVEL=DEBUG
python src/mcp_orchestrator/server.py
```

## ü§ù Contribui√ß√£o

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/AmazingFeature`)
3. Commit suas mudan√ßas (`git commit -m 'Add some AmazingFeature'`)
4. Push para a branch (`git push origin feature/AmazingFeature`)
5. Abra um Pull Request

### Desenvolvimento

```bash
# Instalar em modo desenvolvimento
pip install -e .

# Executar testes antes de commit
make test
make lint
```

## üìÑ Licen√ßa

Este projeto est√° licenciado sob a Licen√ßa MIT - veja o arquivo [LICENSE](LICENSE) para detalhes.

## üôè Agradecimentos

- [FastMCP](https://github.com/jlowin/fastmcp) - Framework MCP
- [Anthropic](https://anthropic.com/) - Claude API
- [Google AI](https://ai.google.dev/) - Gemini API
- [Ollama](https://ollama.ai/) - LLMs locais

## üìû Suporte

- üìß Email: [seu-email@exemplo.com]
- üêõ Issues: [GitHub Issues](https://github.com/seu-usuario/mcp-orchestrator/issues)
- üìñ Documenta√ß√£o: [docs/](docs/)

---

**‚≠ê Se este projeto te ajudou, considere dar uma estrela no reposit√≥rio!** 