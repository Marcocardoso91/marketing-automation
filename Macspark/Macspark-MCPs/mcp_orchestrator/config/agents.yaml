# Configuração de Agentes do MCP Orchestrator
# Este arquivo define os agentes disponíveis, suas configurações e cadeias de fallback

agents:
  # === AGENTES DE API ===
  
  claude_api:
    enabled: true
    priority: 1
    model: "claude-3-sonnet-20240229"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_cli", "gemini_api", "gemini_cli", "ollama"]
    description: "Claude API - Agente principal de alta qualidade"
    
  gemini_api:
    enabled: true
    priority: 2
    model: "gemini-1.5-pro-latest"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["gemini_cli", "claude_cli", "ollama"]
    description: "Gemini API - Alternativa rápida e eficiente"
    
  openai_api:
    enabled: true
    priority: 3
    model: "gpt-4-turbo-preview"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_api", "gemini_api", "ollama"]
    description: "OpenAI API - GPT-4 para tarefas complexas"
    
  mistral_api:
    enabled: true
    priority: 4
    model: "mistral-large-latest"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_api", "gemini_api", "ollama"]
    description: "Mistral API - Modelo europeu de alta qualidade"
    
  cohere_api:
    enabled: true
    priority: 5
    model: "command-r-plus"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_api", "gemini_api", "ollama"]
    description: "Cohere API - Especializado em tarefas específicas"
    
  perplexity_api:
    enabled: true
    priority: 6
    model: "llama-3.1-sonar-small-128k-online"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_api", "gemini_api", "ollama"]
    description: "Perplexity API - Acesso à internet em tempo real"
    
  # === AGENTES CLI ===
  
  claude_cli:
    enabled: true
    priority: 7
    model: "claude-3-sonnet-20240229"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["gemini_cli", "ollama"]
    description: "Claude CLI - Versão local do Claude"
    
  gemini_cli:
    enabled: true
    priority: 8
    model: "gemini-1.5-pro-latest"
    max_tokens: 2048
    timeout: 30
    fallback_chain: ["claude_cli", "ollama"]
    description: "Gemini CLI - Versão local do Gemini"
    
  # === LLMs LOCAIS ===
  
  ollama:
    enabled: true
    priority: 9
    model: "llama3.1:8b"
    max_tokens: 2048
    timeout: 60
    fallback_chain: ["lm_studio"]
    description: "Ollama - LLM local gratuito"
    
  lm_studio:
    enabled: true
    priority: 10
    model: "llama-3.1-8b-instruct"
    max_tokens: 2048
    timeout: 60
    fallback_chain: ["ollama"]
    description: "LM Studio - LLM local alternativo"
    
  # === CONFIGURAÇÕES ESPECIALIZADAS ===
  
  # Agente para código
  code_specialist:
    enabled: true
    priority: 1
    model: "claude-3-sonnet-20240229"
    max_tokens: 4096
    timeout: 45
    fallback_chain: ["claude_cli", "gemini_api", "ollama"]
    description: "Especialista em código - Modelos otimizados para programação"
    
  # Agente para análise
  analysis_specialist:
    enabled: true
    priority: 2
    model: "claude-3-sonnet-20240229"
    max_tokens: 4096
    timeout: 45
    fallback_chain: ["gemini_api", "openai_api", "ollama"]
    description: "Especialista em análise - Modelos otimizados para análise de dados"
    
  # Agente para criatividade
  creative_specialist:
    enabled: true
    priority: 3
    model: "gemini-1.5-pro-latest"
    max_tokens: 4096
    timeout: 45
    fallback_chain: ["claude_api", "openai_api", "ollama"]
    description: "Especialista em criatividade - Modelos otimizados para geração criativa"

# === CONFIGURAÇÕES GLOBAIS ===

global_settings:
  # Configurações de fallback
  max_fallback_attempts: 3
  fallback_delay: 1.0
  
  # Configurações de cache
  enable_cache: true
  cache_ttl: 3600  # 1 hora
  
  # Configurações de rate limiting
  rate_limit_enabled: true
  rate_limit_per_minute: 60
  
  # Configurações de logging
  log_agent_calls: true
  log_fallback_events: true
  
  # Configurações de segurança
  max_prompt_length: 10000
  max_response_length: 50000
  sanitize_inputs: true
  sanitize_outputs: true
  
  # Configurações de monitoramento
  enable_metrics: true
  health_check_interval: 30

# === MODELOS DISPONÍVEIS ===

available_models:
  claude:
    - "claude-3-sonnet-20240229"
    - "claude-3-haiku-20240307"
    - "claude-3-opus-20240229"
  
  gemini:
    - "gemini-1.5-pro-latest"
    - "gemini-1.5-flash-latest"
    - "gemini-1.0-pro"
  
  openai:
    - "gpt-4-turbo-preview"
    - "gpt-4"
    - "gpt-3.5-turbo"
  
  mistral:
    - "mistral-large-latest"
    - "mistral-medium-latest"
    - "mistral-small-latest"
  
  cohere:
    - "command-r-plus"
    - "command-r"
    - "command-light"
  
  perplexity:
    - "llama-3.1-sonar-small-128k-online"
    - "llama-3.1-sonar-medium-128k-online"
    - "llama-3.1-sonar-large-128k-online"
  
  ollama:
    - "llama3.1:8b"
    - "llama3.1:70b"
    - "codellama:7b"
    - "codellama:13b"
    - "mistral:7b"
    - "mistral:13b"
    - "phi3:3.8b"
    - "phi3:14b"
  
  lm_studio:
    - "llama-3.1-8b-instruct"
    - "llama-3.1-70b-instruct"
    - "codellama-7b-instruct"
    - "codellama-13b-instruct"
    - "mistral-7b-instruct"
    - "mistral-13b-instruct"

# === CONFIGURAÇÕES DE CUSTO ===

cost_optimization:
  # Priorizar agentes gratuitos
  prefer_free_agents: true
  
  # Ordem de preferência por custo (menor para maior)
  cost_priority:
    - "ollama"
    - "lm_studio"
    - "claude_cli"
    - "gemini_cli"
    - "perplexity_api"
    - "cohere_api"
    - "mistral_api"
    - "gemini_api"
    - "openai_api"
    - "claude_api"
  
  # Limites de custo por mês (em USD)
  monthly_budget: 50.0
  
  # Alertas de custo
  cost_alerts:
    - threshold: 25.0
      action: "warn"
    - threshold: 40.0
      action: "limit"
    - threshold: 50.0
      action: "disable_paid" 