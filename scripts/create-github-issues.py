#!/usr/bin/env python3
"""
Script para criar Issues no GitHub automaticamente
Baseado na An√°lise T√©cnica Completa

Uso:
    python create-github-issues.py --token YOUR_GITHUB_TOKEN --repo owner/repo

Ou configure as vari√°veis de ambiente:
    export GITHUB_TOKEN=your_token
    export GITHUB_REPO=owner/repo
    python create-github-issues.py
"""

import os
import sys
import requests
import argparse
from typing import List, Dict

# Configura√ß√£o
ISSUES = [
    # P0 - CR√çTICOS
    {
        "title": "[P0][SECURITY] Credenciais reais expostas no .env versionado",
        "body": """## üî¥ CR√çTICO - Seguran√ßa

**Arquivo**: `api/.env`

### Descri√ß√£o
Credenciais reais est√£o versionadas no git:
- `SECRET_KEY=823ef04b24287aa6973613172ebad191...`
- `N8N_API_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...`
- `NOTION_API_TOKEN=ntn_44266321668aTZt11zd3cpnXj8z...`

### Impacto
üî• **CR√çTICO** - Comprometimento total do sistema se o reposit√≥rio for p√∫blico ou acessado por terceiros.

### Solu√ß√£o
```bash
# 1. Remover do git
git rm --cached api/.env

# 2. Atualizar .gitignore
echo "**/.env" >> .gitignore
echo ".env.*" >> .gitignore
echo "!.env.example" >> .gitignore

# 3. Rotacionar TODAS as credenciais
# - Gerar novo SECRET_KEY
# - Recriar N8N_API_KEY
# - Recriar NOTION_API_TOKEN

# 4. Commit e push
git add .gitignore
git commit -m "security: remove .env and add to gitignore"
git push
```

### Checklist
- [ ] Remover .env do git
- [ ] Atualizar .gitignore
- [ ] Rotacionar SECRET_KEY
- [ ] Rotacionar N8N_API_KEY
- [ ] Rotacionar NOTION_API_TOKEN
- [ ] Verificar hist√≥rico do git (considerar git filter-branch se necess√°rio)
- [ ] Configurar secrets no CI/CD
- [ ] Documentar processo em .env.example

### Esfor√ßo Estimado
‚è±Ô∏è 2-3 horas

### Prioridade
üî¥ P0 - RESOLVER IMEDIATAMENTE (primeiras 24h)
""",
        "labels": ["security", "p0", "critical", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P0][SECURITY] TokenBlacklist em mem√≥ria perde estado ao reiniciar",
        "body": """## üî¥ CR√çTICO - Seguran√ßa

**Arquivo**: `api/src/utils/security.py:99-132`

### Descri√ß√£o
A classe `TokenBlacklist` usa `set()` em mem√≥ria para armazenar tokens revogados. Ao reiniciar o servidor, todos os tokens revogados voltam a ser v√°lidos.

```python
class TokenBlacklist:
    def __init__(self):
        self._blacklist: Set[str] = set()  # ‚ùå Mem√≥ria vol√°til
```

### Impacto
üî¥ **ALTO** - Usu√°rios que:
- Fizeram logout
- Trocaram senha
- Tiveram tokens revogados

...podem continuar usando tokens antigos ap√≥s restart do servidor.

### Solu√ß√£o
Migrar para Redis com TTL autom√°tico:

```python
import redis
import hashlib
from datetime import datetime

class RedisTokenBlacklist:
    def __init__(self, redis_client: redis.Redis):
        self.redis = redis_client

    def add(self, token: str, expiry: datetime):
        token_hash = hashlib.sha256(token.encode()).hexdigest()
        ttl = int((expiry - datetime.utcnow()).total_seconds())
        self.redis.setex(f"blacklist:{token_hash}", ttl, "1")

    def is_blacklisted(self, token: str) -> bool:
        token_hash = hashlib.sha256(token.encode()).hexdigest()
        return self.redis.exists(f"blacklist:{token_hash}") > 0
```

### Checklist
- [ ] Adicionar redis ao docker-compose.yml
- [ ] Adicionar redis-py ao requirements.txt
- [ ] Implementar RedisTokenBlacklist
- [ ] Atualizar dependency injection
- [ ] Adicionar testes
- [ ] Documentar no README

### Esfor√ßo Estimado
‚è±Ô∏è 2 horas

### Prioridade
üî¥ P0 - RESOLVER IMEDIATAMENTE
""",
        "labels": ["security", "p0", "bug", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P0][ARCH] Integra√ß√£o MCP completamente n√£o implementada",
        "body": """## üü† ALTO - Arquitetura

**Arquivos**:
- `api/src/integrations/notion_client.py`
- `api/src/integrations/n8n_manager.py`

### Descri√ß√£o
C√≥digo de integra√ß√£o MCP s√£o apenas placeholders que logam warnings:

```python
async def create_campaign_report(self, campaign_data: Dict) -> Optional[str]:
    logger.warning("Notion integration not available - returning mock ID")
    return None  # ‚ùå Sempre retorna None
```

A documenta√ß√£o promete features que n√£o existem.

### Impacto
üü† **ALTO** - Features documentadas n√£o funcionam:
- Cria√ß√£o autom√°tica de reports no Notion
- Cria√ß√£o de workflows no n8n via API
- Sincroniza√ß√£o de dados

### Decis√£o Necess√°ria

**Op√ß√£o A**: Implementar realmente (16-24h)
- Usar MCP servers configurados
- Implementar cliente MCP real
- Testes de integra√ß√£o

**Op√ß√£o B**: Cleanup e docs honestas (2h)
- Remover c√≥digo placeholder
- Atualizar docs para "Planejado"
- Criar issues de feature para futuro

### Recomenda√ß√£o
üí° Op√ß√£o B por enquanto (cleanup). Criar roadmap para Op√ß√£o A em Q1 2026.

### Checklist
- [ ] Decidir: Implementar ou remover?
- [ ] Se implementar: criar spike t√©cnico
- [ ] Se remover: deletar c√≥digo placeholder
- [ ] Atualizar toda documenta√ß√£o
- [ ] Comunicar stakeholders

### Esfor√ßo Estimado
‚è±Ô∏è 2h (cleanup) ou 16-24h (implementa√ß√£o)

### Prioridade
üü† P0/P1 - Decis√£o necess√°ria na Sprint 1
""",
        "labels": ["architecture", "p0", "decision-needed", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P0][PERF] FacebookAdsAgent recriado a cada request",
        "body": """## üü† ALTO - Performance

**Arquivo**: `api/src/api/campaigns.py:16-22`

### Descri√ß√£o
O `Depends(get_facebook_agent)` cria nova inst√¢ncia do FacebookAdsAgent em **CADA request**:

```python
def get_facebook_agent() -> FacebookAdsAgent:
    return FacebookAdsAgent()  # ‚ùå Nova inst√¢ncia toda vez
```

Isso faz:
- Valida√ß√£o de token no Facebook API (HTTP request externo)
- Inicializa√ß√£o do FacebookAdsApi
- ~300-500ms de lat√™ncia extra por request

### Impacto
üî¥ **ALTO**:
- Lat√™ncia desnecess√°ria (+300-500ms/request)
- Rate limit do Facebook API desperdi√ßado
- CPU/mem√≥ria desperdi√ßados

### Solu√ß√£o
Implementar singleton com cache TTL:

```python
import time
from typing import Optional

_agent_cache: Optional[FacebookAdsAgent] = None
_agent_cache_time: Optional[float] = None
CACHE_TTL = 3600  # 1 hora

def get_facebook_agent() -> FacebookAdsAgent:
    global _agent_cache, _agent_cache_time

    now = time.time()

    # Cache miss ou expirado
    if _agent_cache is None or (now - _agent_cache_time) > CACHE_TTL:
        _agent_cache = FacebookAdsAgent()
        _agent_cache_time = now
        logger.info("Created new FacebookAdsAgent instance (cache miss)")

    return _agent_cache
```

### Alternativa: Dependency com cache no FastAPI
```python
from functools import lru_cache

@lru_cache(maxsize=1)
def get_cached_facebook_agent() -> FacebookAdsAgent:
    return FacebookAdsAgent()
```

### Checklist
- [ ] Implementar singleton com TTL
- [ ] Adicionar m√©tricas (cache hits/misses)
- [ ] Testes de concorr√™ncia
- [ ] Documentar comportamento
- [ ] Monitorar impacto na lat√™ncia

### Esfor√ßo Estimado
‚è±Ô∏è 1 hora

### Prioridade
üî¥ P0 - RESOLVER Sprint 1
""",
        "labels": ["performance", "p0", "optimization", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P0][DB] Migration faltando para coluna hashed_password",
        "body": """## üî¥ CR√çTICO - Database

**Arquivo**: `api/alembic/versions/001_initial_schema.py`

### Descri√ß√£o
O model `User` define `hashed_password`:

```python
# api/src/models/user.py:19
class User(Base):
    hashed_password: Mapped[str] = mapped_column(String, nullable=False)
```

Mas a migration inicial N√ÉO cria essa coluna!

```python
# 001_initial_schema.py
op.create_table(
    'users',
    sa.Column('id', ...),
    sa.Column('email', ...),
    # ‚ùå FALTA hashed_password
)
```

### Impacto
üî• **CR√çTICO** - Sistema de autentica√ß√£o quebrado em produ√ß√£o:
- Deploy vai falhar
- Login n√£o funciona
- `IntegrityError` ao criar usu√°rios

### Solu√ß√£o
Adicionar coluna na migration `002_add_user_auth_fields.py` (se existir) ou criar nova:

```python
# alembic/versions/002_add_hashed_password.py
def upgrade():
    op.add_column(
        'users',
        sa.Column('hashed_password', sa.String(), nullable=False,
                  server_default='')  # Tempor√°rio para migra√ß√£o
    )

    # Depois de migra√ß√£o, remover server_default
    op.alter_column('users', 'hashed_password', server_default=None)

def downgrade():
    op.drop_column('users', 'hashed_password')
```

### Checklist
- [ ] Criar migration 002
- [ ] Testar upgrade em DB vazio
- [ ] Testar downgrade
- [ ] Atualizar seed data se existir
- [ ] Documentar no CHANGELOG

### Esfor√ßo Estimado
‚è±Ô∏è 30 minutos

### Prioridade
üî¥ P0 - BLOCKER para produ√ß√£o
""",
        "labels": ["database", "p0", "critical", "migration", "sprint-1"],
        "milestone": 1
    },

    # P1 - ALTOS
    {
        "title": "[P1][CODE] 43 exce√ß√µes gen√©ricas sem contexto adequado",
        "body": """## üü† ALTO - Qualidade de C√≥digo

**Localiza√ß√£o**: 43 ocorr√™ncias em `api/src/`

### Descri√ß√£o
Tratamento gen√©rico de erros que:
- Esconde problemas reais
- Exp√µe stack traces sens√≠veis
- Dificulta debugging

```python
except Exception as e:
    logger.error(f"Error: {e}")  # ‚ùå Log gen√©rico
    raise HTTPException(
        status_code=500,
        detail=str(e)  # ‚ùå Exp√µe stack trace
    )
```

### Impacto
- Debugging muito dif√≠cil em produ√ß√£o
- Informa√ß√µes sens√≠veis vazadas
- Imposs√≠vel criar alertas espec√≠ficos

### Solu√ß√£o
Criar hierarquia de exce√ß√µes:

```python
# src/exceptions.py
class MacsparkException(Exception):
    pass

class ExternalAPIError(MacsparkException):
    pass

class FacebookAPIError(ExternalAPIError):
    pass

class RateLimitError(FacebookAPIError):
    pass

# Uso
try:
    response = facebook_api.call()
except RateLimitError:
    raise HTTPException(429, detail="Rate limit exceeded")
except FacebookAPIError as e:
    logger.error("Facebook API error", extra={"error": str(e)})
    raise HTTPException(502, detail="External API unavailable")
```

### Checklist
- [ ] Criar arquivo src/exceptions.py
- [ ] Definir hierarquia de exce√ß√µes
- [ ] Refatorar 43 ocorr√™ncias
- [ ] Adicionar testes
- [ ] Documentar no CONTRIBUTING.md

### Esfor√ßo Estimado
‚è±Ô∏è 4-6 horas

### Prioridade
üü† P1 - Sprint 1
""",
        "labels": ["code-quality", "p1", "refactoring", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P1][RESILIENCE] Implementar Circuit Breaker pattern",
        "body": """## üü† ALTO - Resili√™ncia

**Localiza√ß√£o**: Todas chamadas a APIs externas

### Descri√ß√£o
Sem circuit breaker, se Facebook API ficar lento/indispon√≠vel:
- Sistema continua tentando indefinidamente
- Threads/workers ficam bloqueados
- Cascade failure para outras partes do sistema

### Impacto
Sistema pode ficar completamente inutiliz√°vel por falha externa.

### Solu√ß√£o
Implementar com `pybreaker`:

```python
from pybreaker import CircuitBreaker
from facebook_business.exceptions import FacebookRequestError

# Configura√ß√£o
facebook_breaker = CircuitBreaker(
    fail_max=5,              # Abre ap√≥s 5 falhas
    timeout_duration=60,      # Reabre ap√≥s 60s
    expected_exception=FacebookRequestError,
    name="facebook_api"
)

# Uso
@facebook_breaker
async def call_facebook_api(endpoint: str, params: dict):
    response = await facebook_client.get(endpoint, params=params)
    return response.json()

# Handler para circuit aberto
@app.exception_handler(CircuitBreakerError)
async def circuit_breaker_handler(request, exc):
    return JSONResponse(
        status_code=503,
        content={"detail": "Service temporarily unavailable"}
    )
```

### Features
- [ ] Circuit Breaker para Facebook API
- [ ] Circuit Breaker para n8n
- [ ] Circuit Breaker para Notion
- [ ] M√©tricas Prometheus
- [ ] Dashboard Grafana
- [ ] Alertas

### Checklist
- [ ] Adicionar pybreaker ao requirements.txt
- [ ] Implementar decorators
- [ ] Configurar thresholds
- [ ] Adicionar testes
- [ ] Documentar comportamento
- [ ] Monitorar em produ√ß√£o

### Esfor√ßo Estimado
‚è±Ô∏è 3-4 horas

### Prioridade
üü† P1 - Sprint 1
""",
        "labels": ["resilience", "p1", "enhancement", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P1][CODE] Duplica√ß√£o de c√≥digo: dois wrappers de API Facebook",
        "body": """## üü° M√âDIO - Code Smell

**Arquivos**:
- `api/src/utils/api_client.py` - wrapper vazio
- `shared/marketing_shared/utils/facebook_client.py` - implementa√ß√£o real

### Descri√ß√£o
Camada de indire√ß√£o desnecess√°ria que confunde:

```python
# api/src/utils/api_client.py
from marketing_shared.utils.facebook_client import FacebookClient

def get_api_client():
    return FacebookClient()  # Apenas um alias!
```

### Impacto
- Confus√£o para novos desenvolvedores
- Camada extra sem valor
- Dificulta refatora√ß√£o

### Solu√ß√£o
```bash
# Remover o wrapper
rm api/src/utils/api_client.py

# Atualizar imports
# De:
from src.utils.api_client import get_api_client
# Para:
from marketing_shared.utils.facebook_client import FacebookClient
```

### Checklist
- [ ] Identificar todas as refer√™ncias
- [ ] Atualizar imports
- [ ] Remover arquivo
- [ ] Rodar testes
- [ ] Atualizar docs se necess√°rio

### Esfor√ßo Estimado
‚è±Ô∏è 1 hora

### Prioridade
üü° P1 - Sprint 1 ou 2
""",
        "labels": ["code-quality", "p1", "refactoring", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P1][TEST] Muitos testes configurados como skip",
        "body": """## üü† ALTO - Testes

**Arquivo**: `api/tests/test_suite_completa.py:12-14`

### Descri√ß√£o
Testes marcados para skip quando n√£o h√° `.env` ou n8n:

```python
skip_if_no_env = pytest.mark.skipif(
    not HAS_ENV_FILE,
    reason=".env file not available"
)

skip_n8n_e2e = pytest.mark.skipif(...)

# Resultado: Testes n√£o rodam em CI!
```

### Impacto
- Cobertura real de testes desconhecida
- CI/CD pode passar com bugs
- Falsa sensa√ß√£o de seguran√ßa

### Solu√ß√£o
Criar fixtures com mocks para 100% dos testes rodarem:

```python
# conftest.py
import pytest
from unittest.mock import Mock

@pytest.fixture
def mock_facebook_api(monkeypatch):
    mock = Mock()
    mock.get_campaign.return_value = {
        "id": "123",
        "name": "Test Campaign"
    }
    monkeypatch.setattr("src.agents.facebook_agent.FacebookAdsApi", mock)
    return mock

# Reorganizar estrutura
tests/
‚îú‚îÄ‚îÄ unit/          # Sempre rodam (com mocks)
‚îú‚îÄ‚îÄ integration/   # Requerem .env (Docker)
‚îî‚îÄ‚îÄ e2e/          # Manual (staging)
```

### Checklist
- [ ] Criar mocks para todas depend√™ncias externas
- [ ] Reorganizar testes em unit/integration/e2e
- [ ] Configurar pytest.ini
- [ ] Atualizar CI/CD
- [ ] Documentar em CONTRIBUTING.md
- [ ] Meta: 80%+ cobertura em unit tests

### Esfor√ßo Estimado
‚è±Ô∏è 6-8 horas

### Prioridade
üü† P1 - Sprint 1
""",
        "labels": ["testing", "p1", "ci-cd", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P1][OBS] Celery tasks sem m√©tricas de erro",
        "body": """## üü† ALTO - Observabilidade

**Arquivo**: `api/src/tasks/celery_app.py:26-43`

### Descri√ß√£o
Tasks agendadas mas sem instrumenta√ß√£o:

```python
'collect-metrics-30min': {
    'task': 'src.tasks.collectors.collect_facebook_metrics',
    'schedule': 1800.0,
    # ‚ùå Sem error handlers
    # ‚ùå Sem m√©tricas
    # ‚ùå Sem alertas
},
```

### Impacto
Tasks podem falhar silenciosamente por semanas sem ningu√©m saber.

### Solu√ß√£o
Adicionar handlers e m√©tricas:

```python
from celery.signals import task_failure, task_success
from prometheus_client import Counter

# M√©tricas
celery_task_failures = Counter(
    'celery_task_failures_total',
    'Total de falhas em tasks Celery',
    ['task_name']
)

celery_task_success = Counter(
    'celery_task_success_total',
    'Total de sucessos em tasks Celery',
    ['task_name']
)

# Handlers
@task_failure.connect
def task_failure_handler(sender=None, task_id=None, exception=None, **kwargs):
    logger.error(
        f"Task {sender.name} failed",
        extra={
            "task_id": task_id,
            "error": str(exception),
            "task_name": sender.name
        }
    )
    celery_task_failures.labels(task=sender.name).inc()

    # Alertar no Slack se cr√≠tico
    if is_critical_task(sender.name):
        send_slack_alert(f"üî• Task cr√≠tica falhou: {sender.name}")

@task_success.connect
def task_success_handler(sender=None, **kwargs):
    celery_task_success.labels(task=sender.name).inc()
```

### Checklist
- [ ] Implementar signal handlers
- [ ] Adicionar m√©tricas Prometheus
- [ ] Configurar alertas (Slack/email)
- [ ] Dashboard Grafana para tasks
- [ ] Documentar no RUNBOOK.md
- [ ] Testes

### Esfor√ßo Estimado
‚è±Ô∏è 2-3 horas

### Prioridade
üü† P1 - Sprint 1
""",
        "labels": ["observability", "p1", "celery", "sprint-1"],
        "milestone": 1
    },
    {
        "title": "[P1][PERF] √çndices de banco de dados faltando",
        "body": """## üü° M√âDIO - Performance

**Arquivo**: `api/alembic/versions/`

### Descri√ß√£o
Queries comuns sem √≠ndices otimizados:

```sql
-- ‚ùå Lento: buscar hist√≥rico de conversas
SELECT * FROM conversation_memory
WHERE user_id = ?
ORDER BY timestamp DESC
LIMIT 50;

-- ‚ùå Lento: listar campanhas ativas recentes
SELECT * FROM campaigns
WHERE status = 'ACTIVE'
ORDER BY updated_time DESC;
```

### Impacto
Queries ficam lentas com crescimento de dados.

### Solu√ß√£o
Criar migration com √≠ndices compostos:

```python
# 003_add_performance_indexes.py
def upgrade():
    # Hist√≥rico de conversas
    op.create_index(
        'idx_conversation_memory_user_timestamp',
        'conversation_memory',
        ['user_id', 'timestamp'],
        postgresql_using='btree'
    )

    # Campanhas ativas
    op.create_index(
        'idx_campaigns_status_updated',
        'campaigns',
        ['status', 'updated_time'],
        postgresql_using='btree'
    )

def downgrade():
    op.drop_index('idx_conversation_memory_user_timestamp')
    op.drop_index('idx_campaigns_status_updated')
```

### Checklist
- [ ] Analisar slow query log
- [ ] Identificar queries N+1
- [ ] Criar √≠ndices compostos
- [ ] Testar performance antes/depois
- [ ] Documentar no README
- [ ] Monitorar tamanho dos √≠ndices

### Esfor√ßo Estimado
‚è±Ô∏è 1-2 horas

### Prioridade
üü° P1 - Sprint 2
""",
        "labels": ["performance", "p1", "database", "sprint-2"],
        "milestone": 2
    },

    # P2 - M√âDIOS (selecionar alguns importantes)
    {
        "title": "[P2][CODE] Valida√ß√£o de token s√≠ncrona em c√≥digo async",
        "body": """## üü° M√âDIO - Code Quality

**Arquivo**: `api/src/utils/token_manager.py:20-39`

### Descri√ß√£o
`_check_token_validity()` usa `requests.get()` s√≠ncrono em contexto async:

```python
def _check_token_validity(self) -> bool:
    response = requests.get(url, params=params, timeout=30)  # BLOCKING!
```

### Impacto
Bloqueia event loop ‚Üí reduz throughput do servidor.

### Solu√ß√£o
Usar `httpx.AsyncClient`:

```python
async def _check_token_validity(self) -> bool:
    async with httpx.AsyncClient() as client:
        response = await client.get(url, params=params, timeout=30)
        return response.status_code == 200
```

### Esfor√ßo
‚è±Ô∏è 2 horas

### Prioridade
üü° P2 - Sprint 2
""",
        "labels": ["code-quality", "p2", "async", "sprint-2"],
        "milestone": 2
    },
    {
        "title": "[P2][DOCS] Documenta√ß√£o duplicada e inconsistente",
        "body": """## üü° M√âDIO - Documenta√ß√£o

**Localiza√ß√£o**:
- `README.md` raiz vs `api/README.md` vs `analytics/README.md`
- `api/docs/prd/facebook-ads-agent/*` vs `analytics/docs/prd/agente-facebook/*`

### Problema
READMEs com informa√ß√µes conflitantes, PRDs duplicados.

### Impacto
Novos desenvolvedores ficam confusos.

### Solu√ß√£o
Consolidar em `docs/` centralizado:

```
docs/
‚îú‚îÄ‚îÄ README.md (√≠ndice principal)
‚îú‚îÄ‚îÄ architecture/
‚îú‚îÄ‚îÄ api/
‚îú‚îÄ‚îÄ analytics/
‚îî‚îÄ‚îÄ prd/
    ‚îî‚îÄ‚îÄ agente-facebook/ (fonte √∫nica)

# READMEs de subprojetos apenas linkam
api/README.md ‚Üí "Ver docs/ para documenta√ß√£o completa"
```

### Esfor√ßo
‚è±Ô∏è 4-6 horas

### Prioridade
üü° P2 - Sprint 2
""",
        "labels": ["documentation", "p2", "sprint-2"],
        "milestone": 2
    },
    {
        "title": "[P2][DEPS] Depend√™ncias duplicadas entre api/ e analytics/",
        "body": """## üü° M√âDIO - DevOps

**Arquivos**:
- `api/requirements.txt` - 58 linhas
- `analytics/scripts/requirements.txt` - 25 linhas
- Duplica√ß√µes: `requests`, `python-dotenv`, `openai`

### Problema
Sem gerenciamento centralizado de vers√µes ‚Üí conflitos.

### Solu√ß√£o
Migrar para estrutura monorepo:

```
requirements/
‚îú‚îÄ‚îÄ base.txt (compartilhado)
‚îú‚îÄ‚îÄ api.txt (-r base.txt + espec√≠ficos)
‚îî‚îÄ‚îÄ analytics.txt (-r base.txt + espec√≠ficos)
```

### Esfor√ßo
‚è±Ô∏è 3-4 horas

### Prioridade
üü° P2 - Sprint 2
""",
        "labels": ["dependencies", "p2", "devops", "sprint-2"],
        "milestone": 2
    },
    {
        "title": "[P2][PERF] Falta de pagina√ß√£o em endpoints de listagem",
        "body": """## üü° M√âDIO - Performance

**Arquivo**: `api/src/api/campaigns.py:25`

### Descri√ß√£o
Endpoints podem retornar milhares de registros sem pagina√ß√£o.

### Solu√ß√£o
Implementar cursor-based pagination:

```python
@router.get("/")
async def list_campaigns(
    cursor: Optional[str] = None,
    limit: int = Query(50, le=100)
) -> PaginatedResponse[Campaign]:
    ...
```

### Esfor√ßo
‚è±Ô∏è 3 horas

### Prioridade
üü° P2 - Sprint 2
""",
        "labels": ["performance", "p2", "api", "sprint-2"],
        "milestone": 2
    },

    # P3 - BAIXOS (selecionar alguns representativos)
    {
        "title": "[P3][CODE] TODOs no c√≥digo n√£o trackados",
        "body": """## üü¢ BAIXO - Manuten√ß√£o

**Localiza√ß√£o**: 7 TODOs espalhados no c√≥digo

Exemplos:
- `api/src/agents/facebook_agent.py:237` - "TODO: Replace with LangChain"
- `api/src/api/automation.py:131` - "TODO: Implement database query in Sprint 4"

### Solu√ß√£o
Criar issues para cada TODO ou implementar/remover.

### Esfor√ßo
‚è±Ô∏è 2 horas

### Prioridade
üü¢ P3 - Backlog
""",
        "labels": ["maintenance", "p3", "backlog"],
        "milestone": 3
    },
    {
        "title": "[P3][OBS] Logs sem correlation IDs",
        "body": """## üü¢ BAIXO - Observabilidade

**Problema**: Logs sem `request_id` para correlacionar entre servi√ßos.

### Solu√ß√£o
Middleware que injeta `request_id`:

```python
import uuid
from contextvars import ContextVar

request_id_ctx = ContextVar('request_id', default=None)

@app.middleware("http")
async def add_request_id(request: Request, call_next):
    request_id = str(uuid.uuid4())
    request_id_ctx.set(request_id)
    response = await call_next(request)
    response.headers["X-Request-ID"] = request_id
    return response
```

### Esfor√ßo
‚è±Ô∏è 3 horas

### Prioridade
üü¢ P3 - Backlog
""",
        "labels": ["observability", "p3", "backlog"],
        "milestone": 3
    },
    {
        "title": "[P3][DEPS] Vers√µes de depend√™ncias defasadas",
        "body": """## üü¢ BAIXO - Depend√™ncias

Vers√µes antigas em `api/requirements.txt`:
- `fastapi==0.104.1` (atual: 0.110+)
- `openai==1.3.7` (atual: 1.50+)
- `langchain==0.0.340`

### Solu√ß√£o
```bash
pip-audit
pip install --upgrade fastapi openai langchain
pytest  # Rodar testes
```

### Esfor√ßo
‚è±Ô∏è 3-4 horas (com testes)

### Prioridade
üü¢ P3 - Backlog
""",
        "labels": ["dependencies", "p3", "security", "backlog"],
        "milestone": 3
    },
    {
        "title": "[P3][OPS] Configurar n8n inicial - 0 workflows detectados",
        "body": """## ‚ö†Ô∏è OPERACIONAL - Configura√ß√£o Inicial

**Descoberta**: An√°lise do PostgreSQL mostrou:
- ‚úÖ n8n instalado e rodando
- ‚ùå **0 workflows configurados**
- ‚ùå **0 execu√ß√µes registradas**
- ‚ùå **0 credenciais configuradas**

### Diagn√≥stico
Sistema pronto mas completamente vazio. Precisa configura√ß√£o inicial.

### A√ß√£o Recomendada

1. **Importar workflows**:
```bash
# Copiar workflows para n8n
cp analytics/n8n-workflows/*.json /path/to/n8n/workflows/

# Ou importar via UI
# http://n8n.macspark.dev ‚Üí Import from File
```

2. **Configurar credenciais**:
- Facebook Ads API
- Notion API
- Supabase
- OpenAI (se usar)

3. **Ativar workflows essenciais**:
- Meta Ads ‚Üí Supabase (coleta de m√©tricas)
- Notion Reports (gera√ß√£o de relat√≥rios)

### Checklist
- [ ] Importar workflows de analytics/n8n-workflows/
- [ ] Configurar credenciais Facebook
- [ ] Configurar credenciais Notion
- [ ] Configurar credenciais Supabase
- [ ] Ativar workflow de coleta (30min interval)
- [ ] Testar execu√ß√£o manual
- [ ] Verificar logs de execu√ß√£o
- [ ] Documentar em docs/n8n-setup.md

### Esfor√ßo Estimado
‚è±Ô∏è 2-4 horas (configura√ß√£o inicial)

### Prioridade
üü° P2 - Sprint 1 ou 2 (operacional importante)
""",
        "labels": ["operations", "p2", "configuration", "n8n", "sprint-2"],
        "milestone": 2
    },
]

def create_issue(repo: str, token: str, issue_data: Dict) -> Dict:
    """Cria uma issue no GitHub via API"""
    url = f"https://api.github.com/repos/{repo}/issues"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    response = requests.post(url, json=issue_data, headers=headers)
    response.raise_for_status()
    return response.json()

def create_milestone(repo: str, token: str, title: str, description: str) -> int:
    """Cria um milestone e retorna o ID"""
    url = f"https://api.github.com/repos/{repo}/milestones"
    headers = {
        "Authorization": f"token {token}",
        "Accept": "application/vnd.github.v3+json"
    }

    data = {
        "title": title,
        "description": description,
        "state": "open"
    }

    response = requests.post(url, json=data, headers=headers)
    response.raise_for_status()
    return response.json()["number"]

def main():
    parser = argparse.ArgumentParser(description="Criar Issues no GitHub")
    parser.add_argument("--token", help="GitHub Personal Access Token")
    parser.add_argument("--repo", help="Reposit√≥rio (owner/repo)")
    parser.add_argument("--dry-run", action="store_true", help="Apenas simular")
    args = parser.parse_args()

    # Obter configura√ß√µes
    token = args.token or os.getenv("GITHUB_TOKEN")
    repo = args.repo or os.getenv("GITHUB_REPO")

    if not token or not repo:
        print("‚ùå Erro: GITHUB_TOKEN e GITHUB_REPO s√£o obrigat√≥rios")
        print("\nUso:")
        print("  python create-github-issues.py --token YOUR_TOKEN --repo owner/repo")
        print("\nOu configure vari√°veis de ambiente:")
        print("  export GITHUB_TOKEN=your_token")
        print("  export GITHUB_REPO=owner/repo")
        sys.exit(1)

    print(f">> Criando {len(ISSUES)} issues no repositorio {repo}")
    print(f"{'=' * 60}\n")

    # Criar milestones primeiro
    milestones = {}
    if not args.dry_run:
        try:
            milestones[1] = create_milestone(
                repo, token,
                "Sprint 1 - Criticos & Seguran√ßa",
                "Resolver problemas P0 e P1 cr√≠ticos de seguran√ßa e performance"
            )
            milestones[2] = create_milestone(
                repo, token,
                "Sprint 2 - Qualidade & Performance",
                "Melhorias de c√≥digo, testes e performance"
            )
            milestones[3] = create_milestone(
                repo, token,
                "Sprint 3 - DevOps & Docs",
                "Melhorias de DevOps, documenta√ß√£o e manuten√ß√£o"
            )
            print(f"[OK] Milestones criados: {milestones}\n")
        except Exception as e:
            print(f"[WARN] Erro ao criar milestones (podem ja existir): {e}\n")

    # Criar issues
    created = 0
    for idx, issue in enumerate(ISSUES, 1):
        try:
            if args.dry_run:
                print(f"[DRY-RUN] {idx}/{len(ISSUES)}: {issue['title']}")
            else:
                # Atualizar milestone ID se foi criado
                if "milestone" in issue and issue["milestone"] in milestones:
                    issue["milestone"] = milestones[issue["milestone"]]

                result = create_issue(repo, token, issue)
                print(f"[OK] {idx}/{len(ISSUES)}: Issue #{result['number']} - {issue['title']}")
                print(f"   URL: {result['html_url']}\n")
                created += 1

        except Exception as e:
            print(f"[ERROR] {idx}/{len(ISSUES)}: Erro ao criar '{issue['title']}': {e}\n")

    print(f"\n{'=' * 60}")
    print(f">> Concluido! {created}/{len(ISSUES)} issues criadas com sucesso")
    print(f"\n>> Resumo:")
    print(f"   - P0 (Critico): 5 issues")
    print(f"   - P1 (Alto): 6 issues")
    print(f"   - P2 (Medio): 9 issues")
    print(f"   - P3 (Baixo): 5 issues")
    print(f"\n>> Acesse: https://github.com/{repo}/issues")
    print(f">> Project Board: https://github.com/{repo}/projects")

if __name__ == "__main__":
    main()
